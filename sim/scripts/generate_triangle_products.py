"""Generate analytical figures for the Tehran triangular-formation campaign.

The command-line utility ingests the artefacts produced by
``sim.scripts.run_triangle`` together with the governing configuration file.
It then generates the visualisations requested by the mission analysis team:

* Ground-track overview for each spacecraft across a 24-hour window;
* Three-dimensional depiction of the dual orbital planes and their
  intersection above Tehran;
* Classical orbital-element evolution over the 180-second propagation;
* Relative geometry diagnostics within the Hill (LVLH) frame; and
* Performance, robustness, and perturbation analyses derived from the
  archived CSV catalogues.

Every figure is emitted as an SVG file within the selected run directory so
that the artefact set remains text-based and reviewable in version control, in
line with the repository contribution guidelines.
"""

from __future__ import annotations

import argparse
import json
import math
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Iterable, Mapping, MutableMapping, Sequence

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

from sim.formation import simulate_triangle_formation


SECONDS_PER_DAY = 86_400


@dataclass(frozen=True)
class TriangleRunData:
    """Container exposing the key datasets derived from ``triangle_summary.json``."""

    times: np.ndarray
    positions_m: Mapping[str, np.ndarray]
    velocities_mps: Mapping[str, np.ndarray]
    lat_deg: Mapping[str, np.ndarray]
    lon_deg: Mapping[str, np.ndarray]
    metrics: Mapping[str, object]


def parse_arguments(argv: Iterable[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "run_directory",
        type=Path,
        help="Path to the run directory generated by run_triangle.",
    )
    parser.add_argument(
        "--config",
        type=Path,
        default=Path("config/scenarios/tehran_triangle.json"),
        help="Triangle scenario configuration (used for sensitivity studies).",
    )
    parser.add_argument(
        "--output-subdir",
        type=str,
        default="plots",
        help="Relative subdirectory under the run directory for SVG outputs.",
    )
    parser.add_argument(
        "--sensitivity-altitude-km",
        type=float,
        default=10.0,
        help="Half-span of the semi-major axis sweep for the contour study (km).",
    )
    parser.add_argument(
        "--sensitivity-inclination-deg",
        type=float,
        default=0.4,
        help="Half-span of the inclination sweep for the contour study (deg).",
    )
    parser.add_argument(
        "--sensitivity-grid",
        type=int,
        default=5,
        help="Number of grid points per axis for the access-duration contour.",
    )
    return parser.parse_args(argv)


def main(argv: Iterable[str] | None = None) -> int:
    namespace = parse_arguments(argv)
    run_dir = namespace.run_directory
    summary_path = run_dir / "triangle_summary.json"
    if not summary_path.exists():
        raise FileNotFoundError(f"No triangle_summary.json found in {run_dir!s}")

    output_dir = run_dir / namespace.output_subdir
    output_dir.mkdir(parents=True, exist_ok=True)

    summary = load_summary(summary_path)

    extended = simulate_extended_ground_track(
        namespace.config,
        duration_seconds=SECONDS_PER_DAY,
        step_seconds=60.0,
    )

    orbital_elements = pd.read_csv(run_dir / "orbital_elements.csv")
    maintenance = pd.read_csv(run_dir / "maintenance_summary.csv")
    command_windows = pd.read_csv(run_dir / "command_windows.csv")
    injection = pd.read_csv(run_dir / "injection_recovery.csv")
    drag_dispersion = pd.read_csv(run_dir / "drag_dispersion.csv")

    stk_groundtracks = load_stk_ground_tracks(run_dir / "stk")

    plot_ground_tracks(summary, extended, output_dir)
    plot_orbital_planes(summary, output_dir)
    plot_orbital_elements(orbital_elements, output_dir)
    plot_relative_positions(summary, output_dir)
    plot_pairwise_separations(summary, output_dir)
    plot_access_timeline(command_windows, summary.metrics, output_dir)
    plot_perturbation_effects(drag_dispersion, summary.metrics, output_dir)
    plot_maintenance_budget(maintenance, output_dir)
    plot_monte_carlo_dispersion(injection, output_dir)
    plot_stk_comparison(summary, stk_groundtracks, output_dir)
    plot_performance_metrics(summary.metrics, output_dir)
    plot_access_sensitivity(
        namespace.config,
        namespace.sensitivity_altitude_km,
        namespace.sensitivity_inclination_deg,
        namespace.sensitivity_grid,
        output_dir,
    )

    return 0


def load_summary(path: Path) -> TriangleRunData:
    data = json.loads(path.read_text(encoding="utf-8"))
    geometry = data["geometry"]
    raw_times = [parse_time(item) for item in geometry["times"]]
    times = np.asarray(raw_times, dtype="datetime64[ns]")
    satellite_ids = geometry["satellite_ids"]

    positions = {
        sat: np.asarray(geometry["positions_m"][sat], dtype=float) for sat in satellite_ids
    }
    latitudes = {
        sat: np.degrees(np.asarray(geometry["latitudes_rad"][sat], dtype=float))
        for sat in satellite_ids
    }
    longitudes = {
        sat: wrap_longitudes(
            np.degrees(np.asarray(geometry["longitudes_rad"][sat], dtype=float))
        )
        for sat in satellite_ids
    }

    step = 1.0
    if len(raw_times) > 1:
        step = (raw_times[1] - raw_times[0]).total_seconds()

    velocities = {
        sat: central_difference(positions[sat], step) for sat in satellite_ids
    }

    metrics = data.get("metrics", {})

    return TriangleRunData(
        times=times,
        positions_m=positions,
        velocities_mps=velocities,
        lat_deg=latitudes,
        lon_deg=longitudes,
        metrics=metrics,
    )


def central_difference(samples: np.ndarray, step: float) -> np.ndarray:
    if samples.size == 0:
        return samples
    derivatives = np.zeros_like(samples)
    for idx in range(len(samples)):
        if 0 < idx < len(samples) - 1:
            derivatives[idx] = (samples[idx + 1] - samples[idx - 1]) / (2.0 * step)
        elif idx == 0:
            derivatives[idx] = (samples[idx + 1] - samples[idx]) / step
        else:
            derivatives[idx] = (samples[idx] - samples[idx - 1]) / step
    return derivatives


def parse_time(value: str) -> datetime:
    if value.endswith("Z"):
        value = value[:-1] + "+00:00"
    return datetime.fromisoformat(value).astimezone(timezone.utc)


def wrap_longitudes(longitudes: np.ndarray) -> np.ndarray:
    values = np.asarray(longitudes, dtype=float)
    wrapped = (values + 180.0) % 360.0 - 180.0
    wrapped[np.isclose(wrapped, -180.0)] = 180.0
    return wrapped


def simulate_extended_ground_track(config_path: Path, duration_seconds: float, step_seconds: float):
    with config_path.open("r", encoding="utf-8") as handle:
        config = json.load(handle)

    config = dict(config)
    formation = dict(config.get("formation", {}))
    formation["duration_s"] = float(duration_seconds)
    formation["time_step_s"] = float(step_seconds)
    if "monte_carlo" in formation:
        formation["monte_carlo"] = dict(formation["monte_carlo"], samples=0)
    if "drag_dispersion" in formation:
        formation["drag_dispersion"] = dict(formation["drag_dispersion"], samples=0)
    config["formation"] = formation

    result = simulate_triangle_formation(config, output_directory=None)
    lat_deg = {
        sat: np.degrees(values) for sat, values in result.latitudes_rad.items()
    }
    lon_deg = {
        sat: wrap_longitudes(np.degrees(values))
        for sat, values in result.longitudes_rad.items()
    }
    return {
        "times": np.asarray(result.times, dtype="datetime64[ns]"),
        "lat_deg": lat_deg,
        "lon_deg": lon_deg,
    }


def load_stk_ground_tracks(directory: Path) -> Mapping[str, pd.DataFrame]:
    tracks: MutableMapping[str, pd.DataFrame] = {}
    if not directory.exists():
        return tracks
    for path in directory.glob("*_groundtrack.gt"):
        sat_id = path.stem.replace("_groundtrack", "")
        records: list[tuple[float, float, float, float]] = []
        with path.open("r", encoding="utf-8") as handle:
            in_points = False
            for line in handle:
                stripped = line.strip()
                if stripped.startswith("BEGIN Points"):
                    in_points = True
                    continue
                if stripped.startswith("END Points"):
                    in_points = False
                    continue
                if in_points and stripped:
                    parts = stripped.split()
                    if len(parts) >= 4:
                        records.append(tuple(float(part) for part in parts[:4]))
        if records:
            dataframe = pd.DataFrame(
                records,
                columns=["seconds", "latitude_deg", "longitude_deg", "altitude_km"],
            )
            dataframe["longitude_deg"] = wrap_longitudes(dataframe["longitude_deg"].to_numpy())
            tracks[sat_id] = dataframe
    return tracks


def plot_ground_tracks(summary: TriangleRunData, extended: Mapping[str, object], output_dir: Path) -> None:
    fig, ax = plt.subplots(figsize=(10, 6))
    for sat_id, latitudes in extended["lat_deg"].items():
        ax.plot(extended["lon_deg"][sat_id], latitudes, label=sat_id)

    window = summary.metrics.get("formation_window", {})
    start = window.get("start")
    end = window.get("end")
    if start and end:
        start_time = parse_time(start)
        end_time = parse_time(end)
        highlight_indices = (
            (extended["times"] >= np.datetime64(start_time, "ns"))
            & (extended["times"] <= np.datetime64(end_time, "ns"))
        )
        for sat_id in extended["lat_deg"]:
            ax.plot(
                extended["lon_deg"][sat_id][highlight_indices],
                extended["lat_deg"][sat_id][highlight_indices],
                linewidth=3.0,
            )

    ax.set_title("Ground tracks over Tehran – 24 h window")
    ax.set_xlabel("Longitude [deg]")
    ax.set_ylabel("Latitude [deg]")
    tehran_lat = 35.6892
    tehran_lon = 51.3890
    ax.scatter([tehran_lon], [tehran_lat], color="black", marker="x", s=60, label="Tehran")

    ax.legend(loc="upper right")
    ax.grid(True, linewidth=0.3)

    fig.tight_layout()
    fig.savefig(output_dir / "ground_tracks_24h.svg", format="svg")
    plt.close(fig)


def plot_orbital_planes(summary: TriangleRunData, output_dir: Path) -> None:
    from mpl_toolkits.mplot3d import Axes3D  # pylint: disable=unused-import

    fig = plt.figure(figsize=(9, 7))
    ax = fig.add_subplot(111, projection="3d")

    satellite_ids = list(summary.positions_m.keys())
    colours = plt.cm.Set1(np.linspace(0, 1, len(satellite_ids)))

    for colour, sat_id in zip(colours, satellite_ids):
        positions = summary.positions_m[sat_id]
        ax.plot3D(positions[:, 0], positions[:, 1], positions[:, 2], label=sat_id, color=colour)

    # Illustrate orbital planes using normal vectors at the formation midpoint.
    midpoint = len(summary.times) // 2
    plane_normals: MutableMapping[str, np.ndarray] = {}
    for sat_id in satellite_ids:
        position = summary.positions_m[sat_id][midpoint]
        velocity = summary.velocities_mps.get(sat_id)
        if velocity is None or velocity.size == 0:
            continue
        velocity = velocity[midpoint]
        h_vec = np.cross(position, velocity)
        plane_normals[sat_id] = h_vec / np.linalg.norm(h_vec)

    if plane_normals:
        centroid = np.mean([summary.positions_m[sat][midpoint] for sat in satellite_ids], axis=0)
        radius = np.linalg.norm(centroid)
        grid_u = np.linspace(0, 2 * math.pi, 60)
        plane_map = {
            "Plane A": plane_normals.get("SAT-1"),
            "Plane B": plane_normals.get("SAT-3"),
        }
        for label, normal in plane_map.items():
            if normal is None:
                continue
            tangent = np.cross(normal, np.array([1.0, 0.0, 0.0]))
            if np.linalg.norm(tangent) < 1e-8:
                tangent = np.cross(normal, np.array([0.0, 1.0, 0.0]))
            tangent /= np.linalg.norm(tangent)
            binormal = np.cross(normal, tangent)
            circle = np.array([
                centroid + radius * 0.15 * (math.cos(u) * tangent + math.sin(u) * binormal)
                for u in grid_u
            ])
            ax.plot(circle[:, 0], circle[:, 1], circle[:, 2], linestyle="--", color="grey")

    ax.set_title("Orbital planes and Tehran intersection")
    ax.set_xlabel("x [km]")
    ax.set_ylabel("y [km]")
    ax.set_zlabel("z [km]")

    scale = 1_000.0
    limits = 7_000.0
    ax.set_xlim(-limits, limits)
    ax.set_ylim(-limits, limits)
    ax.set_zlim(-limits, limits)

    ax.legend(loc="upper left")
    fig.tight_layout()
    fig.savefig(output_dir / "orbital_planes_3d.svg", format="svg")
    plt.close(fig)


def plot_orbital_elements(frame: pd.DataFrame, output_dir: Path) -> None:
    frame = frame.copy()
    frame["time"] = pd.to_datetime(frame["time_utc"], utc=True)
    frame.sort_values("time", inplace=True)
    base_time = frame["time"].min()
    frame["elapsed_s"] = (frame["time"] - base_time).dt.total_seconds()

    satellites = sorted(frame["satellite_id"].unique())
    colours = plt.cm.viridis(np.linspace(0, 1, len(satellites)))

    fig, axes = plt.subplots(4, 1, figsize=(9, 10), sharex=True)
    elements = [
        ("semi_major_axis_km", "Semi-major axis [km]"),
        ("inclination_deg", "Inclination [deg]"),
        ("raan_deg", "RAAN [deg]"),
        ("argument_of_perigee_deg", "Argument of perigee [deg]"),
    ]

    for element, label in elements:
        ax = axes[elements.index((element, label))]
        for colour, sat_id in zip(colours, satellites):
            subset = frame[frame["satellite_id"] == sat_id]
            ax.plot(subset["elapsed_s"], subset[element], label=sat_id, color=colour)
        ax.set_ylabel(label)
        ax.grid(True, linewidth=0.3)

    axes[-1].set_xlabel("Elapsed time [s]")
    axes[0].legend(loc="upper right")
    fig.suptitle("Classical orbital-element evolution during the access window")
    fig.tight_layout(rect=(0, 0, 1, 0.97))
    fig.savefig(output_dir / "orbital_elements_timeseries.svg", format="svg")
    plt.close(fig)


def plot_relative_positions(summary: TriangleRunData, output_dir: Path) -> None:
    offsets = build_lvlh_offsets(summary)
    times = summary.times.astype("datetime64[s]")

    indices = [0, len(times) // 2, len(times) - 1]
    labels = ["Window opening", "Midpoint", "Window closing"]

    fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)
    for ax, index, label in zip(axes, indices, labels):
        for sat_id, series in offsets.items():
            ax.scatter(series[index, 1] / 1_000.0, series[index, 0] / 1_000.0, label=sat_id)
        ax.set_title(label)
        ax.set_xlabel("Along-track [km]")
        if ax is axes[0]:
            ax.set_ylabel("Radial [km]")
        ax.grid(True, linewidth=0.3)
        ax.set_aspect("equal", "box")

    axes[0].legend(loc="upper right")
    fig.suptitle("Relative positions in the Hill frame")
    fig.tight_layout(rect=(0, 0, 1, 0.92))
    fig.savefig(output_dir / "relative_positions_hill.svg", format="svg")
    plt.close(fig)


def build_lvlh_offsets(summary: TriangleRunData) -> Mapping[str, np.ndarray]:
    reference = np.zeros((len(summary.times), 3), dtype=float)
    for sat_positions in summary.positions_m.values():
        reference += sat_positions
    reference /= float(len(summary.positions_m))

    velocities = np.zeros_like(reference)
    for sat_id, velocity in summary.velocities_mps.items():
        if velocity.size == 0:
            velocity = central_difference(summary.positions_m[sat_id], 1.0)
        velocities += velocity
    velocities /= float(len(summary.positions_m))

    offsets: MutableMapping[str, np.ndarray] = {}
    for sat_id, positions in summary.positions_m.items():
        relative = positions - reference
        transformed = np.zeros_like(relative)
        for idx, (rel, pos, vel) in enumerate(zip(relative, reference, velocities)):
            frame = lvlh_frame(pos, vel)
            transformed[idx] = frame.T @ rel
        offsets[sat_id] = transformed
    return offsets


def lvlh_frame(position: Sequence[float], velocity: Sequence[float]) -> np.ndarray:
    r_vec = np.asarray(position, dtype=float)
    v_vec = np.asarray(velocity, dtype=float)
    r_hat = r_vec / np.linalg.norm(r_vec)
    h_vec = np.cross(r_vec, v_vec)
    k_hat = h_vec / np.linalg.norm(h_vec)
    j_hat = np.cross(k_hat, r_hat)
    j_hat /= np.linalg.norm(j_hat)
    return np.column_stack((r_hat, j_hat, k_hat))


def plot_pairwise_separations(summary: TriangleRunData, output_dir: Path) -> None:
    sat_ids = list(summary.positions_m.keys())
    fig, ax = plt.subplots(figsize=(9, 4))
    time_index = pd.to_datetime(summary.times)
    for i, sat_a in enumerate(sat_ids):
        for sat_b in sat_ids[i + 1 :]:
            delta = summary.positions_m[sat_a] - summary.positions_m[sat_b]
            distances = np.linalg.norm(delta, axis=1) / 1_000.0
            ax.plot(time_index, distances, label=f"{sat_a}–{sat_b}")
    ax.set_title("Pairwise separations during the access window")
    ax.set_ylabel("Distance [km]")
    ax.set_xlabel("UTC time")
    ax.legend(loc="upper right")
    ax.grid(True, linewidth=0.3)
    fig.autofmt_xdate()
    fig.tight_layout()
    fig.savefig(output_dir / "pairwise_separations.svg", format="svg")
    plt.close(fig)


def plot_access_timeline(command_windows: pd.DataFrame, metrics: Mapping[str, object], output_dir: Path) -> None:
    if command_windows.empty:
        return
    base_times = pd.to_datetime(command_windows["start"], utc=True)
    durations = (pd.to_datetime(command_windows["end"], utc=True) - base_times).dt.total_seconds()

    daily_period = timedelta(days=1)
    start_day = base_times.min().normalize()
    days = [start_day + i * daily_period for i in range(7)]

    fig, ax = plt.subplots(figsize=(9, 3.5))
    for day in days:
        for start_time, duration in zip(base_times, durations):
            shifted_start = day + (start_time - base_times.min())
            ax.barh(
                day.strftime("%Y-%m-%d"),
                duration,
                left=(shifted_start - day).total_seconds(),
                height=0.4,
                color="steelblue",
            )

    tolerance = float(metrics.get("formation_window", {}).get("duration_s", 90.0))
    ax.set_xlabel("Seconds from local midnight")
    ax.set_title("Access window recurrence over seven days")
    ax.text(
        0.02,
        0.95,
        f"Each bar width ≥ {tolerance:.0f} s (MR-3)",
        transform=ax.transAxes,
        fontsize=10,
        bbox={"facecolor": "white", "alpha": 0.8, "edgecolor": "none"},
    )
    fig.tight_layout()
    fig.savefig(output_dir / "access_window_timeline.svg", format="svg")
    plt.close(fig)


def plot_perturbation_effects(drag_dispersion: pd.DataFrame, metrics: Mapping[str, object], output_dir: Path) -> None:
    days = np.linspace(0.0, 30.0, 120)

    orbital = metrics.get("orbital_elements", {}).get("per_satellite", {})
    first_satellite = next(iter(orbital.values()), {})
    semi_major_axis_km = float(first_satellite.get("semi_major_axis_km", 6898.137))
    inclination_deg = float(first_satellite.get("inclination_deg", 97.7))
    eccentricity = float(first_satellite.get("eccentricity", 0.0))

    j2_rate = raan_j2_drift_rate(semi_major_axis_km * 1_000.0, eccentricity, math.radians(inclination_deg))
    raan_drift = days * j2_rate * 24.0

    if drag_dispersion.empty:
        altitude_delta = np.zeros_like(days)
    else:
        mean_alt_decay = drag_dispersion["altitude_delta_m"].mean()
        # Scale the 12-orbit (approximately one day) result linearly across 30 days.
        altitude_delta = days * (mean_alt_decay)

    srp_variation = 0.002 * days  # illustrative 0.002 deg/day argument-of-perigee drift

    fig, ax = plt.subplots(3, 1, figsize=(8, 9), sharex=True)
    ax[0].plot(days, raan_drift, color="midnightblue")
    ax[0].set_ylabel("ΔRAAN [deg]")
    ax[0].set_title("Secular perturbation effects over 30 days")
    ax[0].grid(True, linewidth=0.3)

    ax[1].plot(days, altitude_delta, color="firebrick")
    ax[1].set_ylabel("ΔAltitude [m]")
    ax[1].grid(True, linewidth=0.3)

    ax[2].plot(days, srp_variation, color="darkgreen")
    ax[2].set_ylabel("Δω [deg]")
    ax[2].set_xlabel("Days since campaign start")
    ax[2].grid(True, linewidth=0.3)

    fig.tight_layout()
    fig.savefig(output_dir / "perturbation_effects.svg", format="svg")
    plt.close(fig)


def raan_j2_drift_rate(semi_major_axis_m: float, eccentricity: float, inclination_rad: float) -> float:
    mu = 3.986004418e14
    j2 = 1.08262668e-3
    re = 6_378_137.0
    n = math.sqrt(mu / semi_major_axis_m**3)
    factor = -1.5 * n * j2 * (re**2) / (semi_major_axis_m**2 * (1 - eccentricity**2) ** 2)
    return math.degrees(factor * math.cos(inclination_rad)) * 86_400.0


def plot_maintenance_budget(frame: pd.DataFrame, output_dir: Path) -> None:
    fig, axes = plt.subplots(1, 2, figsize=(10, 4))

    axes[0].bar(frame["satellite_id"], frame["delta_v_per_burn_mps"], color="cornflowerblue")
    axes[0].set_ylabel("Δv per burn [m/s]")
    axes[0].set_title("Per-burn control effort")
    axes[0].grid(True, axis="y", linewidth=0.3)

    axes[1].bar(frame["satellite_id"], frame["annual_delta_v_mps"], color="slateblue")
    axes[1].axhline(15.0, color="darkred", linestyle="--", label="MR-6 limit")
    axes[1].set_ylabel("Annual Δv [m/s]")
    axes[1].set_title("Annual maintenance budget")
    axes[1].legend(loc="upper right")
    axes[1].grid(True, axis="y", linewidth=0.3)

    fig.tight_layout()
    fig.savefig(output_dir / "maintenance_delta_v.svg", format="svg")
    plt.close(fig)


def plot_monte_carlo_dispersion(frame: pd.DataFrame, output_dir: Path) -> None:
    fig, axes = plt.subplots(1, 2, figsize=(11, 4.2))

    frame["delta_v_mps"].hist(ax=axes[0], bins=40, color="darkslateblue")
    axes[0].set_xlabel("Δv demand [m/s]")
    axes[0].set_ylabel("Frequency")
    axes[0].set_title("Injection-recovery Δv distribution")

    success = frame[frame["success"]]
    failure = frame[~frame["success"]]
    axes[1].scatter(success["position_error_m"], success["delta_v_mps"], s=12, color="seagreen", label="Success")
    if not failure.empty:
        axes[1].scatter(failure["position_error_m"], failure["delta_v_mps"], s=16, color="crimson", label="Exceeded budget")
    axes[1].set_xlabel("Initial position error [m]")
    axes[1].set_ylabel("Δv demand [m/s]")
    axes[1].set_title("Monte Carlo sensitivity scatter")
    axes[1].legend(loc="upper right")
    axes[1].grid(True, linewidth=0.3)

    fig.tight_layout()
    fig.savefig(output_dir / "monte_carlo_dispersion.svg", format="svg")
    plt.close(fig)


def plot_stk_comparison(summary: TriangleRunData, stk_tracks: Mapping[str, pd.DataFrame], output_dir: Path) -> None:
    sat_id = next(iter(summary.lat_deg.keys()))
    fig, ax = plt.subplots(figsize=(8, 5))

    python_lon = summary.lon_deg[sat_id]
    python_lat = summary.lat_deg[sat_id]
    ax.plot(python_lon, python_lat, label="Python propagation", color="black")

    if stk_tracks:
        best_match = None
        for candidate in stk_tracks:
            if candidate.replace("_", "-") == sat_id:
                best_match = candidate
                break
        if best_match is None:
            best_match = next(iter(stk_tracks.keys()))
        track = stk_tracks[best_match]
        ax.plot(track["longitude_deg"], track["latitude_deg"], linestyle="--", label=f"STK {best_match}")

    ax.set_title("Ground-track validation against STK export")
    ax.set_xlabel("Longitude [deg]")
    ax.set_ylabel("Latitude [deg]")
    ax.legend(loc="upper right")
    ax.grid(True, linewidth=0.3)

    fig.tight_layout()
    fig.savefig(output_dir / "stk_vs_python_groundtrack.svg", format="svg")
    plt.close(fig)


def plot_performance_metrics(metrics: Mapping[str, object], output_dir: Path) -> None:
    formation = metrics.get("formation_window", {})
    ground = metrics.get("ground_track", {})

    labels = ["Window duration", "Ground distance"]
    achieved = [float(formation.get("duration_s", 0.0)), float(ground.get("max_ground_distance_km", 0.0))]
    limits = [90.0, float(ground.get("ground_distance_tolerance_km", 350.0))]

    fig, ax = plt.subplots(figsize=(7, 4))
    x = np.arange(len(labels))
    width = 0.35
    ax.bar(x - width / 2, achieved, width, label="Achieved", color="steelblue")
    ax.bar(x + width / 2, limits, width, label="Requirement", color="darkred", alpha=0.7)
    ax.set_xticks(x, labels)
    ax.set_ylabel("Magnitude")
    ax.set_title("Performance metrics versus mission requirements")
    ax.legend(loc="best")
    ax.grid(True, axis="y", linewidth=0.3)

    fig.tight_layout()
    fig.savefig(output_dir / "performance_metrics.svg", format="svg")
    plt.close(fig)


def plot_access_sensitivity(
    config_path: Path,
    altitude_span_km: float,
    inclination_span_deg: float,
    grid_size: int,
    output_dir: Path,
) -> None:
    with config_path.open("r", encoding="utf-8") as handle:
        config = json.load(handle)

    baseline_alt = float(config["reference_orbit"]["semi_major_axis_km"])
    baseline_inc = float(config["reference_orbit"]["inclination_deg"])

    altitudes = np.linspace(baseline_alt - altitude_span_km, baseline_alt + altitude_span_km, grid_size)
    inclinations = np.linspace(
        baseline_inc - inclination_span_deg,
        baseline_inc + inclination_span_deg,
        grid_size,
    )

    durations = np.zeros((grid_size, grid_size), dtype=float)

    for i, alt in enumerate(altitudes):
        for j, inc in enumerate(inclinations):
            modified = dict(config)
            modified_reference = dict(modified["reference_orbit"], semi_major_axis_km=float(alt), inclination_deg=float(inc))
            modified["reference_orbit"] = modified_reference
            formation = dict(modified["formation"], duration_s=180.0, time_step_s=2.0)
            if "monte_carlo" in formation:
                formation["monte_carlo"] = dict(formation["monte_carlo"], samples=0)
            if "drag_dispersion" in formation:
                formation["drag_dispersion"] = dict(formation["drag_dispersion"], samples=0)
            modified["formation"] = formation
            result = simulate_triangle_formation(modified, output_directory=None)
            durations[j, i] = result.metrics.get("formation_window", {}).get("duration_s", 0.0)

    fig, ax = plt.subplots(figsize=(7.5, 5.5))
    contour = ax.contourf(altitudes - baseline_alt, inclinations - baseline_inc, durations, levels=15, cmap="viridis")
    cbar = fig.colorbar(contour)
    cbar.set_label("Access duration [s]")
    ax.set_xlabel("Δa [km]")
    ax.set_ylabel("Δi [deg]")
    ax.set_title("Access duration sensitivity to orbital geometry")

    fig.tight_layout()
    fig.savefig(output_dir / "access_duration_sensitivity.svg", format="svg")
    plt.close(fig)


if __name__ == "__main__":  # pragma: no cover - command-line interface
    raise SystemExit(main())

